# Database partitioning is a technique where you split up a huge table into multiple tables and let the database decide which table
  or which partition to hit based on the where clause.

# partitioning :- helps to to avoid querying huge amount of data and work with smaller set of data.

# using an index or full table scanning 100 million row is a lot,that's going to slow things down.
   Index large tables are always slow to query regardless.So what do we do? Partitioning is the idea here is
   break the table down to smaller pieces so we know we only work with so many rolls and instead of a larger set of rules.

 # The quickest way to query a table with a billion rows is to avoid querying a table with a billion rows with the help of Partitioning.

Vertical and Horizontal Partitioning 

Horizontal Partitioning :-  Split table based on rows [Using list or range]
Vertical Partitioning :- Split table based on column. Ex. Large column (Blob)


Partitioning type
  1. Range :- Date ,Id 
  2. List  :- based on value Ex. By Country,State,Zipcode,Catagory
  
  
  https://www.sqlshack.com/database-table-partitioning-sql-server/
  





SELECT
    OBJECT_SCHEMA_NAME(pstats.object_id) AS SchemaName
    ,OBJECT_NAME(pstats.object_id) AS TableName
    ,ps.name AS PartitionSchemeName
    ,ds.name AS PartitionFilegroupName
    ,pf.name AS PartitionFunctionName
    ,CASE pf.boundary_value_on_right WHEN 0 THEN 'Range Left' ELSE 'Range Right' END AS PartitionFunctionRange
    ,CASE pf.boundary_value_on_right WHEN 0 THEN 'Upper Boundary' ELSE 'Lower Boundary' END AS PartitionBoundary
    ,prv.value AS PartitionBoundaryValue
    ,c.name AS PartitionKey
    ,CASE 
        WHEN pf.boundary_value_on_right = 0 
        THEN c.name + ' > ' + CAST(ISNULL(LAG(prv.value) OVER(PARTITION BY pstats.object_id ORDER BY pstats.object_id, pstats.partition_number), 'Infinity') AS VARCHAR(100)) + ' and ' + c.name + ' <= ' + CAST(ISNULL(prv.value, 'Infinity') AS VARCHAR(100)) 
        ELSE c.name + ' >= ' + CAST(ISNULL(prv.value, 'Infinity') AS VARCHAR(100))  + ' and ' + c.name + ' < ' + CAST(ISNULL(LEAD(prv.value) OVER(PARTITION BY pstats.object_id ORDER BY pstats.object_id, pstats.partition_number), 'Infinity') AS VARCHAR(100))
    END AS PartitionRange
    ,pstats.partition_number AS PartitionNumber
    ,pstats.row_count AS PartitionRowCount
    ,p.data_compression_desc AS DataCompression
FROM sys.dm_db_partition_stats AS pstats
INNER JOIN sys.partitions AS p ON pstats.partition_id = p.partition_id
INNER JOIN sys.destination_data_spaces AS dds ON pstats.partition_number = dds.destination_id
INNER JOIN sys.data_spaces AS ds ON dds.data_space_id = ds.data_space_id
INNER JOIN sys.partition_schemes AS ps ON dds.partition_scheme_id = ps.data_space_id
INNER JOIN sys.partition_functions AS pf ON ps.function_id = pf.function_id
INNER JOIN sys.indexes AS i ON pstats.object_id = i.object_id AND pstats.index_id = i.index_id AND dds.partition_scheme_id = i.data_space_id AND i.type <= 1 /* Heap or Clustered Index */
INNER JOIN sys.index_columns AS ic ON i.index_id = ic.index_id AND i.object_id = ic.object_id AND ic.partition_ordinal > 0
INNER JOIN sys.columns AS c ON pstats.object_id = c.object_id AND ic.column_id = c.column_id
LEFT JOIN sys.partition_range_values AS prv ON pf.function_id = prv.function_id AND pstats.partition_number = (CASE pf.boundary_value_on_right WHEN 0 THEN prv.boundary_id ELSE (prv.boundary_id+1) END)
WHERE pstats.object_id = OBJECT_ID('Sales')
ORDER BY TableName, PartitionNumber;



partion documentation.docx
Table Partitioning 
===================== 4413080

Secnario : when you have large table its difficult to manage 
a table which is > 50Gb and >100Gb it called as large table,
this time its difficult to take backup ,index maintenace,
update statistics ,sql queries get slow , load & unload the data( create lock,block)

But in small table up to 1 Gb not have the above problem 


Facttable : contain 
    Pk  clustered index (Occupy 600 GB)
    NCI(8)    (Occupy  400GB)
    

Partition data 
   specify file group 

Secnaroies 1   Query

  you have Fact table for 20 years (1TB) , 5 Billions rows
Ex.    select * from facttansctio where year between 2013 and 2015    
       the above query returns 200Million rows , here the case is 
       you want to get only 2 years range salestransaction( 200 millon rows) but
       the query scan the entire clustered index which is 5 Billions rows.(Bad Performance)

Secnaroies 2  taking Backup
      you have Fact table for 20 years (1TB) , 5 Billions rows
      Let you want to Full back up 
   you have backup plan 
       1. Fullback once a week  and 
       2. Differential backup every day 
  
Fullback up may take over 10 hours So To saving backu up time.How ?
       
    partitioning table (into state and frequently change data) and take file group back up
    So you dont need to take full back every week for state data (less modification/changing data)
    and put this file group only in read only mode.
    Onyl take back up every week more frequently changing data(may take only 2 years data).

Secnaroies 2  Index Maintenace
    let you have 800GB Cluctered Primary key, 
     
    let you have 10GB  Cluctered Primary key and when you do defrag (Rebuild)
     it requuires additional space(10 GB) inside file (it will create another defragmented 10 Gb
     finally it will do partition swich(cause for locking).

    performing index maitenace on large table takes more time & space and acuire locking (rebuild the entire index)
    Instead only update recent table.
  
    Note :- IF you dont perform index maintenance query generate and Execute bad plan
     
        you may think that you are updating recent index 
        but you are  still rebuilding the entire index 

Secnaroies 2  Loading and Uploading data
 
   let you want to insert data into Fact table from staging (source)
     How long does it take (Eg. 5 million rows daily)
   
   Ex : facttransaction table (has record from 2000-2020), 5 billion rows 
    
     the query look
   Ex : facttransaction table (has record from 2000-2020), 5 billion rows 
    
     narrowing down 
page split 
    
   
   




